{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xrv6g1dA_Gbd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Load the Dataset\n",
        "# We split the data: 80% for training, 20% for validation\n",
        "(train_ds, val_ds), ds_info = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True\n",
        ")\n",
        "\n",
        "# 2. Preprocess the Data\n",
        "IMG_SIZE = 150\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def format_image(image, label):\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    # Resize all images to 150x150\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing, shuffle, batch, and optimize for performance\n",
        "train_ds = train_ds.map(format_image).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(format_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# 3. Design the CNN Model\n",
        "model = models.Sequential([\n",
        "    # First Convolutional Block\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Flatten and Dense Layers for Classification\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5), # Dropout prevents overfitting\n",
        "    layers.Dense(1, activation='sigmoid') # Binary output (0 = cat, 1 = dog)\n",
        "])\n",
        "\n",
        "# 4. Compile the Model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 5. Train the Model\n",
        "EPOCHS = 10\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_custom_image(model, img_path):\n",
        "    # 1. Load the image and resize it to match the model's input shape\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "\n",
        "    # 2. Convert the image to a numpy array\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # 3. Normalize the pixel values (just like we did for the training data)\n",
        "    img_array = img_array / 255.0\n",
        "\n",
        "    # 4. Expand dimensions\n",
        "    # The model expects a batch of images: (batch_size, height, width, channels)\n",
        "    # We add an extra dimension to make it (1, 150, 150, 3)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # 5. Make the prediction\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # 6. Interpret the output\n",
        "    # Since we used a sigmoid activation, the output is a single probability\n",
        "    probability = prediction[0][0]\n",
        "\n",
        "    if probability >= 0.5:\n",
        "        print(f\"Prediction: DOG (Probability score: {probability:.4f})\")\n",
        "    else:\n",
        "        print(f\"Prediction: CAT (Probability score: {probability:.4f})\")\n",
        "\n",
        "# --- Test it out ---\n",
        "# Replace this string with the actual location of your image\n",
        "my_image_path = '/content/dog.jpg.jpeg'\n",
        "\n",
        "# Call the function\n",
        "predict_custom_image(model, my_image_path)"
      ],
      "metadata": {
        "id": "xfCRtpW3BYm5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}